# -*- coding: utf-8 -*-
"""Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bUJCf1hXobxSML5BdgDbGm7NFtgoPxPD
"""

from google.colab import drive
drive.mount('/content/gdrive/', force_remount=True)

cd /content/gdrive/MyDrive/deep_learning_covid-main

# Matplotlib
import matplotlib.pyplot as plt
# Numpy
import numpy as np
# Pillow
from PIL import Image
# Torch
import torch
from torch.utils.data import Dataset, DataLoader
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torchvision import transforms
from datetime import datetime

"""# Data Loader"""

# Data loader
class Lung_Train_Dataset(Dataset):

    def __init__(self):
        """
        Constructor for generic Dataset class - simply assembles
        the important parameters in attributes.
        """

        # All images are of size 150 x 150
        self.img_size = (150, 150)

        # Only two classes will be considered here (normal and infected)
        self.classes = {0: 'normal', 1: 'infected_covid', 2: "infected_non_covid"}

        # The dataset consists only of training images
        self.groups = 'train'

        # Number of images in each part of the dataset
        self.dataset_numbers = {'train_normal': 1341, \
                                'train_infected_covid': 1334, \
                                'train_infected_non_covid': 2529}

        # Path to images for different parts of the dataset
        self.dataset_paths = {'train_normal': './dataset/train/normal/', \
                              'train_infected_covid': './dataset/train/infected/covid', \
                              'train_infected_non_covid': './dataset/train/infected/non-covid'}

    def describe(self):
        """
        Descriptor function.
        Will print details about the dataset when called.
        """

        # Generate description
        msg = "This is the training dataset of the Lung Dataset"
        msg += " used for the Small Project Demo in the 50.039 Deep Learning class"
        msg += " in Feb-March 2021. \n"
        msg += "It contains a total of {} images, ".format(sum(self.dataset_numbers.values()))
        msg += "of size {} by {}.\n".format(self.img_size[0], self.img_size[1])
        msg += "The images are stored in the following locations "
        msg += "and each one contains the following number of images:\n"
        for key, val in self.dataset_paths.items():
            msg += " - {}, in folder {}: {} images.\n".format(key, val, self.dataset_numbers[key])
        print(msg)

    def open_img(self, group_val, class_val, index_val):
        """
        Opens image with specified parameters.
        Parameters:
        - group_val should take values in 'train', 'test' or 'val'.
        - class_val variable should be set to 'normal' or 'infected'.
        - index_val should be an integer with values between 0 and the maximal number of images in dataset.
        Returns loaded image as a normalized Numpy array.
        """

        # Asserts checking for consistency in passed parameters
        err_msg = "Error - group_val variable should be set to 'train', 'test' or 'val'."
        assert group_val in self.groups, err_msg

        err_msg = "Error - class_val variable should be set to 'normal' or 'infected'."
        assert class_val in self.classes.values(), err_msg

        max_val = self.dataset_numbers['{}_{}'.format(group_val, class_val)]
        err_msg = "Error - index_val variable should be an integer between 0 and the maximal number of images."
        err_msg += "\n(In {}/{}, you have {} images.)".format(group_val, class_val, max_val)
        err_msg += "\n Your index value is {}".format(index_val)
        assert isinstance(index_val, int), err_msg
        assert index_val >= 0 and index_val <= max_val, err_msg

        # Open file as before
        path_to_file = '{}/{}.jpg'.format(self.dataset_paths['{}_{}'.format(group_val, class_val)], index_val)
        # with open(path_to_file, 'rb') as f:
            # im = np.asarray(Image.open(f)) / 255
        # f.close()
        im = Image.open(path_to_file)
        return im

    def show_img(self, group_val, class_val, index_val):
        """
        Opens, then displays image with specified parameters.
        Parameters:
        - group_val should take values in 'train', 'test' or 'val'.
        - class_val variable should be set to 'normal' or 'infected'.
        - index_val should be an integer with values between 0 and the maximal number of images in dataset.
        """

        # Open image
        im = self.open_img(group_val, class_val, index_val)

        # Display
        plt.imshow(im)

    def __len__(self):
        """
        Length special method, returns the number of images in dataset.
        """

        # Length function
        return sum(self.dataset_numbers.values())

    def test_funct(self):
        print(list(self.dataset_numbers.values()))

    def __getitem__(self, index):
        """
        Getitem special method.
        Expects an integer value index, between 0 and len(self) - 1.
        Returns the image and its label as a one hot vector, both
        in torch tensor format in dataset.
        """
        # Get item special method
        first_val = int(list(self.dataset_numbers.values())[0])
        second_val = int(list(self.dataset_numbers.values())[1])
        if index < first_val:
            class_val = 'normal'
            label =0
        elif index < (second_val+first_val):
            class_val = 'infected_covid'
            index = index - first_val
            label = 1
        else:
            class_val = 'infected_non_covid'
            index = index - first_val - second_val
            label = 2

        im = self.open_img(self.groups, class_val, index)
        train_transforms = transforms.Compose([
                                               transforms.RandomHorizontalFlip(),
                                               transforms.ToTensor(),
                                               transforms.Normalize([0.5],
                                                                    [0.250])])
        im = train_transforms(im)
        return im, label

class Lung_Val_Dataset(Dataset):

    def __init__(self):
        """
        Constructor for generic Dataset class - simply assembles
        the important parameters in attributes.
        """

        # All images are of size 150 x 150
        self.img_size = (150, 150)

        # Only two classes will be considered here (normal and infected)
        self.classes = {0: 'normal', 1: 'infected_covid', 2: "infected_non_covid"}

        # The dataset consists only of validation images
        self.groups = 'val'

        # Number of images in each part of the dataset
        self.dataset_numbers = {'val_normal': 7, \
                                'val_infected_covid': 8, \
                                'val_infected_non_covid': 7}

        # Path to images for different parts of the dataset
        self.dataset_paths = {'val_normal': './dataset/val/normal/', \
                              'val_infected_covid': './dataset/val/infected/covid', \
                              'val_infected_non_covid': './dataset/val/infected/non-covid', }

    def describe(self):
        """
        Descriptor function.
        Will print details about the dataset when called.
        """

        # Generate description
        msg = "This is the validation dataset of the Lung Dataset"
        msg += " used for the Small Project Demo in the 50.039 Deep Learning class"
        msg += " in Feb-March 2021. \n"
        msg += "It contains a total of {} images, ".format(sum(self.dataset_numbers.values()))
        msg += "of size {} by {}.\n".format(self.img_size[0], self.img_size[1])
        msg += "The images are stored in the following locations "
        msg += "and each one contains the following number of images:\n"
        for key, val in self.dataset_paths.items():
            msg += " - {}, in folder {}: {} images.\n".format(key, val, self.dataset_numbers[key])
        print(msg)

    def open_img(self, group_val, class_val, index_val):
        """
        Opens image with specified parameters.
        Parameters:
        - group_val should take values in 'train', 'test' or 'val'.
        - class_val variable should be set to 'normal' or 'infected'.
        - index_val should be an integer with values between 0 and the maximal number of images in dataset.
        Returns loaded image as a normalized Numpy array.
        """

        # Asserts checking for consistency in passed parameters
        err_msg = "Error - group_val variable should be set to 'train', 'test' or 'val'."
        assert group_val in self.groups, err_msg

        err_msg = "Error - class_val variable should be set to 'normal' or 'infected'."
        assert class_val in self.classes.values(), err_msg

        max_val = self.dataset_numbers['{}_{}'.format(group_val, class_val)]
        err_msg = "Error - index_val variable should be an integer between 0 and the maximal number of images."
        err_msg += "\n(In {}/{}, you have {} images.)".format(group_val, class_val, max_val)
        assert isinstance(index_val, int), err_msg
        assert index_val >= 0 and index_val <= max_val, err_msg

        # Open file as before
        path_to_file = '{}/{}.jpg'.format(self.dataset_paths['{}_{}'.format(group_val, class_val)], index_val)
        # with open(path_to_file, 'rb') as f:
            # im = np.asarray(Image.open(f)) / 255
        # f.close()
        im = Image.open(path_to_file)
        
        return im

    def show_img(self, group_val, class_val, index_val):
        """
        Opens, then displays image with specified parameters.
        Parameters:
        - group_val should take values in 'train', 'test' or 'val'.
        - class_val variable should be set to 'normal' or 'infected'.
        - index_val should be an integer with values between 0 and the maximal number of images in dataset.
        """

        # Open image
        im = self.open_img(group_val, class_val, index_val)

        # Display
        plt.imshow(im)

    def __len__(self):
        """
        Length special method, returns the number of images in dataset.
        """

        # Length function
        return sum(self.dataset_numbers.values())

    def __getitem__(self, index):
        """
        Getitem special method.
        Expects an integer value index, between 0 and len(self) - 1.
        Returns the image and its label as a one hot vector, both
        in torch tensor format in dataset.
        """

        # Get item special method
        first_val = int(list(self.dataset_numbers.values())[0])
        second_val = int(list(self.dataset_numbers.values())[1])
        if index < first_val:
            class_val = 'normal'
            label = 0
        elif index < (second_val+first_val):
            class_val = 'infected_covid'
            index = index - first_val
            label = 1
        else:
            class_val = 'infected_non_covid'
            index = index - first_val - second_val
            label = 2
        im = self.open_img(self.groups, class_val, index)
        test_valid_transforms = transforms.Compose([ 
                                      transforms.ToTensor(),
                                      transforms.Normalize([0.5],
                                                           [0.250])])
        im = test_valid_transforms(im)
        return im, label

class Lung_Test_Dataset(Dataset):

    def __init__(self):
        """
        Constructor for generic Dataset class - simply assembles
        the important parameters in attributes.
        """

        # All images are of size 150 x 150
        self.img_size = (150, 150)

        # Only two classes will be considered here (normal and infected)
        self.classes = {0: 'normal', 1: 'infected_covid', 2: "infected_non_covid"}

        # The dataset consists only of test images
        self.groups = 'test'

        # Number of images in each part of the dataset
        self.dataset_numbers = {'test_normal': 234, \
                                'test_infected_covid': 139, \
                                'test_infected_non_covid': 242}

        # Path to images for different parts of the dataset
        self.dataset_paths = {'test_normal': './dataset/test/normal/', \
                              'test_infected_covid': './dataset/test/infected/covid', \
                              'test_infected_non_covid': './dataset/test/infected/non-covid'}

    def describe(self):
        """
        Descriptor function.
        Will print details about the dataset when called.
        """

        # Generate description
        msg = "This is the test dataset of the Lung Dataset"
        msg += " used for the Small Project Demo in the 50.039 Deep Learning class"
        msg += " in Feb-March 2021. \n"
        msg += "It contains a total of {} images, ".format(sum(self.dataset_numbers.values()))
        msg += "of size {} by {}.\n".format(self.img_size[0], self.img_size[1])
        msg += "The images are stored in the following locations "
        msg += "and each one contains the following number of images:\n"
        for key, val in self.dataset_paths.items():
            msg += " - {}, in folder {}: {} images.\n".format(key, val, self.dataset_numbers[key])
        print(msg)

    def open_img(self, group_val, class_val, index_val):
        """
        Opens image with specified parameters.
        Parameters:
        - group_val should take values in 'train', 'test' or 'val'.
        - class_val variable should be set to 'normal' or 'infected'.
        - index_val should be an integer with values between 0 and the maximal number of images in dataset.
        Returns loaded image as a normalized Numpy array.
        """

        # Asserts checking for consistency in passed parameters
        err_msg = "Error - group_val variable should be set to 'train', 'test' or 'val'."
        assert group_val in self.groups, err_msg

        err_msg = "Error - class_val variable should be set to 'normal' or 'infected'."
        assert class_val in self.classes.values(), err_msg

        max_val = self.dataset_numbers['{}_{}'.format(group_val, class_val)]
        err_msg = "Error - index_val variable should be an integer between 0 and the maximal number of images."
        err_msg += "\n(In {}/{}, you have {} images.)".format(group_val, class_val, max_val)
        assert isinstance(index_val, int), err_msg
        assert index_val >= 0 and index_val <= max_val, err_msg

        # Open file as before
        path_to_file = '{}/{}.jpg'.format(self.dataset_paths['{}_{}'.format(group_val, class_val)], index_val)
        with open(path_to_file, 'rb') as f:
            im = np.asarray(Image.open(f)) / 255
        f.close()
        return im

    def show_img(self, group_val, class_val, index_val):
        """
        Opens, then displays image with specified parameters.
        Parameters:
        - group_val should take values in 'train', 'test' or 'val'.
        - class_val variable should be set to 'normal' or 'infected'.
        - index_val should be an integer with values between 0 and the maximal number of images in dataset.
        """

        # Open image
        im = self.open_img(group_val, class_val, index_val)

        # Display
        plt.imshow(im)

    def __len__(self):
        """
        Length special method, returns the number of images in dataset.
        """

        # Length function
        return sum(self.dataset_numbers.values())

    def __getitem__(self, index):
        """
        Getitem special method.
        Expects an integer value index, between 0 and len(self) - 1.
        Returns the image and its label as a one hot vector, both
        in torch tensor format in dataset.
        """

        # Get item special method
        first_val = int(list(self.dataset_numbers.values())[0])
        second_val = int(list(self.dataset_numbers.values())[1])
        if index < first_val:
            class_val = 'normal'
            label = 0
        elif index < (second_val+first_val):
            class_val = 'infected_covid'
            index = index - first_val
            label = 1
        else:
            class_val = 'infected_non_covid'
            index = index - first_val - second_val
            label = 2
        im = self.open_img(self.groups, class_val, index)
        im = transforms.functional.to_tensor(np.array(im)).float()
        return im, label

"""# Training model"""

# Matplotlib
import matplotlib.pyplot as plt
# Numpy
import numpy as np
# Pillow
from PIL import Image
# Torch
import torch
from torch.utils.data import Dataset, DataLoader
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torchvision import transforms
from datetime import datetime
import os

class custom_model_1(nn.Module):
    def __init__(self, output_size, hidden_layer=1024, drop_p=0.5):
        ''' Builds a feedforward network with arbitrary hidden layers.
        
            Arguments
            ---------
            input_size: integer, size of the input
            output_size: integer, size of the output layer
            hidden_layers: list of integers, the sizes of the hidden layers
            drop_p: float between 0 and 1, dropout probability
        '''
        super().__init__()
        
        self.layer1 = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=16, kernel_size=2, bias=False),
                           nn.ReLU(),
                           nn.BatchNorm2d(16),
                           nn.MaxPool2d(2, 2))
        self.layer2 = nn.Sequential(nn.Conv2d(in_channels=16, out_channels=32, kernel_size=1, bias=False),
                           nn.ReLU(),
                           nn.BatchNorm2d(32),
                           nn.MaxPool2d(2, 2))
        self.layer3 = nn.Sequential(nn.Conv2d(in_channels=32, out_channels=64, kernel_size=2, bias=False),
                           nn.ReLU(),
                           nn.BatchNorm2d(64),
                           nn.MaxPool2d(2, 2))
        self.layer4 = nn.Sequential(nn.Conv2d(in_channels=64, out_channels=64, kernel_size=1, bias=False),
                           nn.ReLU(),
                           nn.BatchNorm2d(64),
                           nn.MaxPool2d(2, 2))
        
        self.out = nn.Sequential(
            nn.Flatten(),
            nn.Linear(5184, hidden_layer),
            nn.Dropout(p=drop_p),
            nn.LeakyReLU(0.2),
            nn.Linear(hidden_layer, output_size)
        )
        
    def forward(self, x):
        ''' Forward pass through the network, returns the output logits '''
        
        # Forward through each layer in `hidden_layers`, with ReLU activation and dropout
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)
        x = self.out(x)
        
        return F.log_softmax(x, dim=1)

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        # Conv2D: 1 input channel, 8 output channels, 3 by 3 kernel, stride of 1.
        self.conv1 = nn.Conv2d(1, 4, 3, 1)
        self.fc1 = nn.Linear(87616, 3)

    def forward(self, x):
        x = self.conv1(x)
        x = torch.flatten(x, 1)
        x = self.fc1(x)
        output = F.log_softmax(x, dim = 1)
        return output
def validation(model, testloader, criterion, device):
    test_loss = 0
    accuracy = 0

    for images, labels in testloader:
        images, labels = images.to(device), labels.to(device)

        output = model.forward(images)
        test_loss += criterion(output, labels).item()

        ps = torch.exp(output)
        equality = (labels.data == ps.max(dim=1)[1])
        accuracy += equality.type(torch.FloatTensor).mean()

    return test_loss, accuracy
def test(model,test_loader,criterion,device):
    test_loss = 0
    accuracy = 0

    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)

        output = model.forward(images)
        test_loss += criterion(output, labels).item()

        ps = torch.exp(output)
        equality = (labels.data == ps.max(dim=1)[1])
        accuracy += equality.type(torch.FloatTensor).mean()
    return test_loss, accuracy
def plot_loss(train_loss, val_loss, accuracy):
    if not os.path.exists("./plots"):
        os.mkdir("./plots")
    plt.figure()
    plt.title("Train & Val loss")
    plt.plot(train_loss)
    plt.plot(val_loss)
    plt.xlabel("Epochs")
    plt.ylabel("Loss")
    plt.legend(["train", "val"], loc="upper right")
    plt.savefig(f"plots/trainvVal_loss.png")
    plt.close()
 
    plt.figure()
    plt.title("Val accuracy")
    plt.plot(accuracy)
    plt.xlabel("Epochs")
    plt.ylabel("Accuracy")
    plt.savefig(f"plots/val_accuracy.png")
    plt.close()

# Define function to save checkpoint
def save_checkpoint(model, path):
    checkpoint = {'hidden': model.n_hidden,
                  'out': model.n_out,
                  'labelsdict': model.labelsdict,
                  'state_dict': model.state_dict(),
                  'opti_state_dict': model.optimizer_state_dict,
                  }
    torch.save(checkpoint, path)

def train(train_loader,val_loader,model, optimizer,labeldict,epochs=10):
    criterion = torch.nn.NLLLoss()

    steps=0
    running_loss=0
    print_every=50
    device="cuda"
    model.to(device)
    training_loss_list = []
    val_loss_list = []
    val_accuracy = []
    for e in range(epochs):
        model.train()
        for k, (image, label) in enumerate(train_loader):
        #     print("-----")
            # print(k)
            # print(image[0].shape)
            # print(label.shape)
            image= image.to(device)
            label=label.to(device)
            optimizer.zero_grad()
            predicted_labels = model.forward(image)
            loss= criterion(predicted_labels,label)
            loss.backward()
            optimizer.step()
            test_loss=0
            accuracy=0
            running_loss+=loss.item()
            steps+=1
            if steps%print_every==0:
                with torch.no_grad():
                    model.eval()
                    test_loss, accuracy=validation( model, val_loader,criterion,device)
                dt_string = datetime.now().strftime("%d/%m/%Y %H:%M:%S")
                print("Epoch: {}/{} - ".format(e + 1, epochs),
                      " {} ".format(dt_string),
                      "Training Loss: {:.3f} - ".format(running_loss / print_every),
                      "Validation Loss: {:.3f} - ".format(test_loss / len(val_loader)),
                      "Validation Accuracy: {:.3f}".format(accuracy / len(val_loader)))
                training_loss_list.append(running_loss/print_every)
                val_loss_list.append(test_loss/len(val_loader))
                val_accuracy.append(accuracy/len(val_loader))
            running_loss=0
            model.train()
    # Add model info 
    model.n_hidden = 1024
    model.n_out = len(labeldict)
    model.labelsdict = labeldict
    model.optimizer_state_dict = optimizer.state_dict
    save_checkpoint(model, "./3_classfier_model.h5py")
    plot_loss(training_loss_list, val_loss_list, val_accuracy)
    print("-- End of training --")

"""# Execution and plotting"""

ld_train = Lung_Train_Dataset()
ld_val= Lung_Val_Dataset()
ld_test= Lung_Test_Dataset()

# model = Net()
model = custom_model_1(len(ld_train.classes))
bs_val = 40
learning_rate=0.01
train_loader = DataLoader(ld_train, batch_size = bs_val, shuffle = True)
val_loader=DataLoader(ld_val, batch_size = 1, shuffle = True)
test_loader=DataLoader(ld_test, batch_size = 1, shuffle = True)
optimizer=torch.optim.Adam(model.parameters(), lr=learning_rate)
labeldict = ld_train.classes
# train(train_loader,val_loader,model, optimizer,labeldict,epochs=10)

model = custom_model_1(len(ld_train.classes))
criterion = torch.nn.NLLLoss()
model.to("cuda")

validation(model, val_loader, criterion, "cuda")

imge=[]
labels=[]
pred_labels=[]

for img, label in val_loader:
  imge.append(img)
  img = img.to("cuda")
  pred = model(img)[0]
  labels.append(label)
  pred_label = int(torch.argmax(pred))
  pred_labels.append(int(torch.argmax(pred)))
  # print(img.shape)

validation_loss, accuracy = validation(model, val_loader, criterion, "cuda")

plt.figure(figsize = (20,20),dpi=300)
index=0
for i in range(4):
    for j in range(6):
      
        plt.subplot(6, 4, index+1)
        
        # Remove x-axis and y-axis ticks from plot
        plt.xticks([], [])
        plt.yticks([], [])
        
            
        # Labels for each image subplotx`
        plt.title("Ground truth label: {}\n Predicted label: {}".format(int(label), pred_label),fontsize=10)
        
        # Display image
        plt.imshow(imge[index][0][0])
        index+=1
        if index >21:
          break
        
# Display full plot
plt.suptitle("Validation set pictures with predicted and ground truth labels \n Average performance: {}".format(accuracy), y=1.05)
plt.tight_layout()
plt.show()

from sklearn.metrics import confusion_matrix
confusion_matrix(labels,pred_label)